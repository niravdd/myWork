<!doctype html>
<html class="no-js" lang="en">
<head>
	<title>Telemetry & Analytics’ Pipelines for Game Balancing - GAM310 | AWS re:Invent</title>
	<meta charset="utf-8">
	<meta http-equiv="x-ua-compatible" content="ie=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1 user-scalable=no">

	<!--Favicon-->
	<link rel="icon" type="image/ico" href="https://a0.awsstatic.com/main/images/site/fav/favicon.ico" /> 
	<link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/main/images/site/fav/favicon.ico" /> 
	<link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/main/images/site/touch-icon-iphone-114-precomposed.png" /> 
	<link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/main/images/site/touch-icon-ipad-144-precomposed.png" /> 
	<link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/main/images/site/touch-icon-iphone-114-precomposed.png" /> 
	<link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/main/images/site/touch-icon-ipad-144-precomposed.png" /> 

	<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300,400,700" rel="stylesheet">
	<link rel="stylesheet" href="style.css" type="text/css" media="all">
	<script src="https://sdk.amazonaws.com/js/aws-sdk-2.2.32.min.js"></script>
</head>
<body class="template-aside yellow page-sessions loading" data-page="sessions">
	<div class="video">
		<div class="overlay"></div>
		<video width="100%" height="100%" autoplay loop muted poster="">
			<source src="https://reinvent.awsevents.com/_media/video/hero-yellow.mp4?20170517" type="video/mp4">
			Your browser does not support the video tag.
		</video>
	</div>
	<div class="site-wrapper">
		<div class="site-content">

<header class="site-header">
	<div class="central-column">
		<a class="site-branding" href="/">
			<img src="https://reinvent.awsevents.com/_media/images/branding/aws-reinvent-logo.png" alt="AWS re:Invent 2017 logo" />
			<span class="offscreen">AWS re:Invent</span>
		</a>
	</div>
</header>

<main class="site-main">
	<header class="page-header"> 
		<div class="central-column">
			<div class="text">
				<h2 class="headline-s1">GAM310</h2>
				<h3 class="headline-s2">Telemetry & Analytics’ Pipelines for Game Balancing</h3>
				<p class="lower-link">Welcome to the Workshop!</p>
			</div>
		</div>
	</header>
	<div class="sections body-copy">
		<section id="section-sessions" class="page-section dark">
			<div class="central-column">
				<div class="indent">
					<p class="intro">In this workshop, we build telemetry/analytics data processing pipelines to assist game developers/architects, designers and producers make certain game balancing decisions as well as troubleshooting the game. We work with a fictitious RPG and ingest data for in-game events. We then analyze the data to help with game balancing and other relevant recommendations for game developers and designers. As a participant, you will use Amazon Kinesis, Amazon Kinesis Firehose, Amazon Analytics, Amazon EMR, Amazon Redshift, Amazon S3, Amazon Athena and Amazon QuickSight. Prerequisites include having your own laptop and an interest in big data services, game data processing & analytics. This workshop will benefit developers and architects, in addition to game designers, producers, and others interested in building analytics pipelines on AWS.</p>
					<div class="session">
						<h3>WORKSHOP DETAILS</h3>
						<p>This workshop will be broken down into a series of labs that flow on from each other (that is, you must complete each lab in order before proceeding with the next). The four lab exercises that will be covered are:</p>
						<div class="indent-show">
							<p>Lab 1: Building an Analytics Pipeline</p>
							<p>Lab 2: Building a Serverless Analytics Pipeline</p>
							<p>Lab 3: Performing Analytics on a Stream</p>
							<p>Lab 4: Building a Big Data Analytics Environment</p>
						</div>
						<p>As a reminder, you should have a laptop device (which you likely have if you're reading this) and a clean AWS account, with <span class="bold">AdministratorAccess</span> policy-level access. AWS Credits will be provided to the value of $USD30.</p>
						<p>If you require assistance in any of the lab exercises, please click on the button at the top-right corner of all of the lab instruction pages to request help. A facilitator will come around to your seat when they are available.

						<h3 class="overline">PRE-REQUISITES</h3>
						<p>This workshop has some pre-requisites.</p>
						<div class="indent-show" id="1-1-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-1-button', '1-1-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-1-content">
							<p>1. You must have your own AWS account</p>
							<p>2. You must have administrative privileges associated with an IAM User and have a working <span class="bold">Access Key</span> and <span class="bold">Secret Key</span>. Instructions here: <a href="http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html target="_blank">http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html</a></p>
							<p>3. You must have SSH installed on your computer.</p>
							<p>4. You must have the AWS CLI installed on your computer, and set your AWS CLI Default Region to us-west-2 using <span class="bold">aws configure</span></p>
							<p>5. You must enter your Account ID in the following form to ensure the instructions on this page are personalised. This data is not sent to us, it remains in your browser. If you are unsure what your Account ID is, enter:
								<pre>
aws sts get-caller-identity --query "Account" --output text
								</pre>
							</p>
							<p>
							Account ID: &nbsp;&nbsp;&nbsp;<input type="text" value="" id="accountidinput" name="accountidinput" />&nbsp;
							<button type="button" class="btn" onclick="changetext()">Update script text</button>
							</p>
						</div>

						<h3 class="overline">DEPLOYING A LANDING ZONE</h3>
						<p>You must now set up the landing zone for your data pipelines. For this we will use a bash script!</p>
						<p>This script will create a new VPC, subnets, routes, security groups, create a bastion host, and log in for you.</p>
						<p>Please enter the command <span class="bold"><pre>wget https://s3-us-west-2.amazonaws.com/gam310-2017/baseScript.sh</pre></span> </p>
						<p>or if you're on Windows navigate to that URL, download the file, and using your command shell navigate to the folder you downloaded it to.</p>
						<p>If you have troubles with the CloudFormation, please follow the CLI commands in this section.</p>
						<div class="indent-show" id="1-2-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-2-button', '1-2-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-2-content">
							<p><pre>
aws ec2 create-vpc --cidr-block 10.0.0.0/16
# Replace all following instances of &lt;vpc-id&gt; in this script with the "VpcId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id &lt;vpc-id&gt; --cidr-block 10.0.1.0/24 --availability-zone us-west-2a
# Replace all following instances of &lt;subnet-id1&gt; in this script with the "SubnetId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id &lt;vpc-id&gt; --cidr-block 10.0.2.0/24 --availability-zone us-west-2a
# Replace all following instances of &lt;subnet-id2&gt; in this script with the "SubnetId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id &lt;vpc-id&gt; --cidr-block 10.0.3.0/24 --availability-zone us-west-2a
# Replace all following instances of &lt;subnet-id3&gt; in this script with the "SubnetId" from the JSON that is returned in your console window.

aws ec2 create-internet-gateway
# Replace all following instances of &lt;igw-id&gt; in this script with the "InternetGatewayId" from the JSON that is returned in your console window.

aws ec2 attach-internet-gateway --vpc-id &lt;vpc-id&gt; --internet-gateway-id &lt;igw-id&gt;

aws ec2 create-route-table --vpc-id &lt;vpc-id&gt;
# Replace all following instances of &lt;route-table-id&gt; in this script with the "RouteTableId" from the JSON that is returned in your console window.

aws ec2 create-route --route-table-id &lt;route-table-id&gt; --destination-cidr-block 0.0.0.0/0 --gateway-id &lt;igw-id&gt;

aws ec2 describe-route-tables --route-table-id &lt;route-table-id&gt;
# Verify route has been created correctly. There will be two routes, the first which is the default route showing that traffic destined for the 10.0.0.0/16 network will stay local, and the second of which will be the route you just added, with your "GatewayId" showing and a "DestinationCidrBlock": "0.0.0.0/0" attached to it.

aws ec2 describe-subnets --filters "Name=vpc-id,Values=&lt;vpc-id&gt;" --query 'Subnets[*].{ID:SubnetId,AZ:AvailabilityZone,CIDR:CidrBlock}'
# This should show 3 subnets with the CIDR blocks listed above.

## Associate your first subnet with the public route, making it a public subnet
aws ec2 associate-route-table --subnet-id &lt;subnet-id1&gt; --route-table-id &lt;route-table-id&gt;

## Enable public IP for instances created in the public subnet
aws ec2 modify-subnet-attribute --subnet-id &lt;subnet-id1&gt; --map-public-ip-on-launch

## Create a key pair to use for SSH access into the Bastion Host
aws ec2 create-key-pair --key-name myWorkshopKeyPair --query 'KeyMaterial' --output text &gt; myWorkshopKeyPair.pem

## Grant the file owner (you!) read permission
chmod 400 myWorkshopKeyPair.pem

## Create security groups
aws ec2 create-security-group --group-name BastionHostAccess --description "Allow access for Bastion Host" --vpc-id &lt;vpc-id&gt;
# Replace all following instances of &lt;bastion-security-group-id&gt; in this script with the "GroupId" from the JSON that is returned in your console window.
aws ec2 create-security-group --group-name RedshiftAccess --description "Allow access for Redshift" --vpc-id &lt;vpc-id&gt;
# Replace all following instances of &lt;redshift-security-group-id&gt; in this script with the "GroupId" from the JSON that is returned in your console window.

# Add rule to allow SSH access to the Bastion Host from *anywhere*
aws ec2 authorize-security-group-ingress --group-id &lt;bastion-security-group-id&gt; --protocol tcp --port 22 --cidr 0.0.0.0/0
# Add rule to allow SQL access to the Redshift cluster from anywhere
# TODO IS THIS NECESSARY SEEING THAT WE GRANT ACCESS TO THE BASTION HOST BELOW??? SEEMS A BIT TOO OPEN TO THE WORLD.
aws ec2 authorize-security-group-ingress --group-id &lt;redshift-security-group-id&gt; --protocol tcp --port 5439 --cidr 0.0.0.0/0
# Need to enable FH access to Redshift
aws ec2 authorize-security-group-ingress --group-id &lt;redshift-security-group-id&gt; --protocol tcp --port 5439 --cidr 52.89.255.224/27

# Add rule to allow access to Redshift from Quicksight
aws ec2 authorize-security-group-ingress --group-id &lt;redshift-security-group-id&gt; --protocol tcp --port 5439 --cidr 54.70.204.128/27

## Now create the Bastion Host (based on an AMI we prepared earlier) (Nirav's bastion AMI in us-west-2 is ami-dbec22a3)
aws ec2 run-instances --image-id ami-e2822398 --count 1 --instance-type t2.micro --key-name myWorkshopKeyPair --security-group-ids &lt;bastion-security-group-id&gt; --subnet-id &lt;subnet-id1&gt;
# Replace all following instances of &lt;instance-id&gt; in this script with the "InstanceId" from the JSON that is returned in your console window.

## Get the public IP so that you can connect to it
aws ec2 describe-instances --instance-id &lt;instance-id&gt; --query 'Reservations[*].Instances[*].PublicIpAddress' --output=text
# Replace all following instances of &lt;public-ip-address&gt; in this script with the IP address that is returned in your console window.

# Add rule to allow access to Redshift from the Bastion Host
aws ec2 authorize-security-group-ingress --group-id &lt;redshift-security-group-id&gt; --protocol tcp --port 5439 --cidr &lt;public-ip-address&gt;/32

## Get into the instance
ssh -i myWorkshopKeyPair.pem ec2-user@&lt;public-ip-address&gt;
							</pre>
							</p>
						</div>

						<h3 class="overline">PIPELINE 1 - ANALYTICS PIPELINE</h3>
						<p>Now that you have your Bastion Host configured and have logged in, let's set up your first analytics pipeline!</p>
						<div class="indent-show" id="1-3-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-3-button', '1-3-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-3-content">
							<p>
							<pre>
##Configure the AWS CLI
aws configure
# Use your existing AWS Access Key ID, AWS Secret Access Key, Default region name=us-west-2 and leave the Default output format empty (just hit Enter)

## Store your AWS Account ID as a variable
accountid="$(aws sts get-caller-identity --query "Account" --output text)"
## Create an S3 bucket for your game bot
aws s3api create-bucket --bucket "workshop-bot-${accountid}" --acl private --create-bucket-configuration LocationConstraint=us-west-2

## Download the required policy documents
wget https://s3-us-west-2.amazonaws.com/gam310-2017/iam-base-redshift-policy.json
wget https://s3-us-west-2.amazonaws.com/gam310-2017/iam-redshift-policy.json
wget https://s3-us-west-2.amazonaws.com/gam310-2017/iam-base-fh-policy.json
## Create a role for Redshift from the policy document provided
aws iam create-role --role-name redshift_fullaccess_role --assume-role-policy-document file://iam-base-redshift-policy.json
## Apply a policy to the role to allow full access to Redshift
aws iam put-role-policy --role-name redshift_fullaccess_role --policy-name iam-redshift-policy --policy-document file://iam-redshift-policy.json

## Create your Kinesis stream for telemetry
aws kinesis create-stream --stream-name evalTelemetryStream --shard-count 10
## Create your Kinesis stream for analytics
aws kinesis create-stream --stream-name evalAnalyticsStream --shard-count 10

## Create a role for Firehose from the policy document provided
aws iam create-role --role-name firehose_delivery_role --assume-role-policy-document file://iam-base-fh-policy.json
							</pre>
							</p>
						</div>

						<h3 class="overline">PIPELINE 1 - CHANGE THE FIREHOSE POLICY JSON DOCUMENT</h3>
						<p>You need to change the <span class="bold">iam-fh-policy.json</span> document. Enter the following command:</p>
						<p>
						<pre>
vi iam-fh-policy.json
						</pre>
						</p>
						<p>
						Expand the script below, enter your account number, and hit the "Update script text" button.
						</p>
						<div class="indent-show" id="1-4-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-4-button', '1-4-content')">CLICK TO TOGGLE THE SCRIPT</a></div></div>
						<div class="indent-hide" id="1-4-content">
							<pre>
							<p id="iam-fh-policy">
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "",
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::workshop-bot-%ACCOUNTID%",
                "arn:aws:s3:::workshop-bot-%ACCOUNTID%/*",
                "arn:aws:s3:::%FIREHOSE_BUCKET_NAME%",
                "arn:aws:s3:::%FIREHOSE_BUCKET_NAME%/*"
            ]
        },
        {
          "Sid": "",
          "Effect": "Allow",
          "Action": [
            "lambda:InvokeFunction",
            "lambda:GetFunctionConfiguration"
          ],
          "Resource": "arn:aws:lambda:us-west-2:%ACCOUNTID%:function:KinesisDataGeneratorCognitoSetup:$LATEST"
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Action": [
                "logs:PutLogEvents"
            ],
            "Resource": [
                "arn:aws:logs:us-west-2:%ACCOUNTID%:log-group:/aws/kinesisfirehose/evalAnalyticsFHStream:log-stream:*",
                "arn:aws:logs:us-west-2:%ACCOUNTID%:log-group:/aws/kinesisfirehose/evalTelemetryFHStream:log-stream:*"
            ]
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Action": [
                "kinesis:DescribeStream",
                "kinesis:GetShardIterator",
                "kinesis:GetRecords"
            ],
            "Resource": [
                "arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalAnalyticsStream",
                "arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalTelemetryStream"
            ]
        },
        {
          "Effect": "Allow",
          "Action": [
            "kms:Decrypt"
          ],
          "Resource": [
            "arn:aws:kms:region:accountid:key/DUMMY_KEY_ID"
          ],
          "Condition": {
            "StringEquals": {
              "kms:ViaService": "kinesis.us-west-2.amazonaws.com"
            },
            "StringLike": {
              "kms:EncryptionContext:aws:kinesis:arn": [
                    "arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalTelemetryStream",
                    "arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalAnalyticsStream"
                ]
            }
          }
        }
    ]
}
							</p>
							</pre>
							</div><br />
							<p>
							Highlight the text above, then copy it to your clipboard. Switch back to your console where you should be in vi, hit the "I" key to insert your text, then CTRL-V to paste the text. You then need to hit ESC then type ":wq" to write your changes and quit.
							</p>

						<h3 class="overline">PIPELINE 1 - SET UP LOG GROUPS, GAMEBOT AND REDSHIFT</h3>
						<p>Your Firehose policy is ready to go! Let's apply it, then set up your log groups and Redshift.</p>
						<div class="indent-show" id="1-5-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-5-button', '1-5-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-5-content">
							<p>
							<pre>
## Apply a policy to the role to allow full access to Firehose
aws iam put-role-policy --role-name firehose_delivery_role --policy-name iam-fh-policy --policy-document file://iam-fh-policy.json

## Create a log group and streams for telemetry
aws logs create-log-group  --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream" --log-stream-name "S3Delivery"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream" --log-stream-name "RedshiftDelivery"

## Create a log group and streams for analytics
aws logs create-log-group  --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream" --log-stream-name "S3Delivery"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream" --log-stream-name "RedshiftDelivery"

## Install your gamebot!
sudo yum install php71.x86_64
sudo yum install -y httpd24
sudo service httpd start
sudo chkconfig httpd on
sudo groupadd www
sudo usermod -a -G www ec2-user
sudo chown -R root:www /var/www
sudo chmod 2775 /var/www
sudo find /var/www -type d -exec chmod 2775 {} +
sudo find /var/www -type f -exec chmod 0664 {} +
wget https://s3-us-west-2.amazonaws.com/gam310-2017/kinesis-datagen.tar
sudo tar -xf kinesis-datagen.tar -C /var/www/html/
sudo service httpd restart

## Create Redshift cluster
aws redshift create-cluster-subnet-group --cluster-subnet-group-name workshopsubnetgroup  --description "My subnet group for the workshop" --subnet-ids &lt;subnet-id1&gt; &lt;subnet-id2&gt; &lt;subnet-id3&gt;
aws redshift create-cluster --cluster-identifier workshopcluster --master-username workshopuser --master-user-password workshopP4SSWORD --cluster-type single-node --node-type ds2.xlarge --cluster-type single-node --db-name workshopdb --cluster-subnet-group-name workshopsubnetgroup --vpc-security-group-ids &lt;redshift-security-group-id&gt;

## Connect to the Redshift DB and create the tables in Redshift
pgcli postgres://workshopuser:workshopP4SSWORD@workshopcluster.%REDSHIFTCLUSTER%.us-west-2.redshift.amazonaws.com:5439/workshopdb
create table eval01table (playerip varchar(16), handle varchar(40), email varchar(128), uuid varchar(64), playerid bigint, country varchar(64), useragent varchar(128), datestamp timestamptz, walletbalance real, playerlevel varchar(16), status varchar(16));
create table eval02table (datestamp timestamptz, playerid bigint, playerlevel varchar(16), squadelementmap varchar(8), gamenumber int, squadpower int, squadagility int, squadhealth int, squadluck int, squadspecial int, squadguard int, squaddamage int, squadinventoryitemcount int, bosspower int, bossagility int, bosshealth int, bossluck int, bossspecial int, bossguard int, bossdamage int, result varchar(8));
							</pre>
							</p>
						</div>


						<h3 class="overline">PIPELINE 1 - CHANGE THE FIREHOSE ANALYTICS CONFIGURATION JSON DOCUMENT</h3>
						<p>You need to change the <span class="bold">analyticsInput.json</span> document. First, we need to populate your Firehose configuration document with your Redshift Cluster ID. Enter the following to find out what your Redshift endpoint is:
						<pre>
aws redshift describe-clusters --cluster-identifier workshopcluster --query 'Clusters[0].Endpoint.Address' --output text
						</pre>
						</p>
						<p>
						Redshift Endpoint Address: &nbsp;&nbsp;&nbsp;<input type="text" value="" id="redshiftinput" name="redshiftinput" />&nbsp;
						<button type="button" class="btn" onclick="changeredshifttext()">Update script text</button>
						</p>
						<p>Enter the following command:</p>
						<p>
						<pre>
vi analyticsInput.json
						</pre>
						</p>
						<p>
						Expand the script below, enter your account number, and hit the "Update script text" button.
						</p>
						<div class="indent-show" id="1-6-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-6-button', '1-6-content')">CLICK TO TOGGLE THE SCRIPT</a></div></div>
						<div class="indent-hide" id="1-6-content">
							<pre>
							<p id="analyticsInput">
{
    "RedshiftDestinationConfiguration": {
        "RoleARN": "arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role",
        "ClusterJDBCURL": "jdbc:redshift://%REDSHIFTCLUSTER%:5439/workshopdb",
        "CopyCommand": {
            "DataTableName": "eval01table",
            "DataTableColumns": "playerip, handle, email, uuid, playerid, country, useragent, datestamp, walletbalance, playerlevel, status",
            "CopyOptions": "format as json 'auto' dateformat 'YYYY-MM-DD HH:MI:SS+/-TZ'"
        },
        "Username": "workshopuser",
        "Password": "workshopP4SSWORD",
        "RetryOptions": {
            "DurationInSeconds": 3600
        },
        "S3Configuration": {
            "RoleARN": "arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role",
            "BucketARN": "arn:aws:s3:::kinesis-bot-datagen",
            "Prefix": "eval01table",
            "BufferingHints": {
                "SizeInMBs": 5,
                "IntervalInSeconds": 300
            },
            "CompressionFormat": "UNCOMPRESSED",
            "EncryptionConfiguration": {
                "NoEncryptionConfig": "NoEncryption"
            },
            "CloudWatchLoggingOptions": {
                "Enabled": true,
                "LogGroupName": "/aws/kinesisfirehose/evalAnalyticsFHStream",
                "LogStreamName": "S3Delivery"
            }
        },
        "ProcessingConfiguration": {
            "Enabled": false
        },
        "S3BackupMode": "Disabled",
        "CloudWatchLoggingOptions": {
            "Enabled": true,
            "LogGroupName": "/aws/kinesisfirehose/evalAnalyticsFHStream",
            "LogStreamName": "RedshiftDelivery"
        }
    }
}
							</p>
							</pre>
							</div><br />
							<p>
							Highlight the text above, then copy it to your clipboard. Switch back to your console where you should be in vi, hit the "I" key to insert your text, then CTRL-V to paste the text. You then need to hit ESC then type ":wq" to write your changes and quit.
							</p>

						<h3 class="overline">PIPELINE 1 - CHANGE THE FIREHOSE TELEMETRY CONFIGURATION JSON DOCUMENT</h3>
						<p>You need to change the <span class="bold">telemetryInput.json</span> document. Enter the following command:</p>
						<p>
						<pre>
vi telemetryInput.json
						</pre>
						</p>
						<p>
						Expand the script below, enter your account number, and hit the "Update script text" button.
						</p>
						<div class="indent-show" id="1-7-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-7-button', '1-7-content')">CLICK TO TOGGLE THE SCRIPT</a></div></div>
						<div class="indent-hide" id="1-7-content">
							<pre>
							<p id="telemetryInput">
{
    "RedshiftDestinationConfiguration": {
        "RoleARN": "arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role",
        "ClusterJDBCURL": "jdbc:redshift://%REDSHIFTCLUSTER%:5439/evaldatabase",
        "CopyCommand": {
            "DataTableName": "eval02table",
            "DataTableColumns": "datestamp, playerid, playerlevel, gamenumber, squadpower, squadagility, squadhealth, squadluck, squadspecial, bosspower, bossagility, bosshealth, bossluck, bossspecial, result",
            "CopyOptions": "format as json 'auto' dateformat 'YYYY-MM-DD HH:MI:SS+/-TZ'"
        },
        "Username": "workshopuser",
        "Password": "workshopP4SSWORD",
        "RetryOptions": {
            "DurationInSeconds": 3600
        },
        "S3Configuration": {
            "RoleARN": "arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role",
            "BucketARN": "arn:aws:s3:::kinesis-bot-datagen",
            "Prefix": "eval02table",
            "BufferingHints": {
                "SizeInMBs": 5,
                "IntervalInSeconds": 60
            },
            "CompressionFormat": "UNCOMPRESSED",
            "EncryptionConfiguration": {
                "NoEncryptionConfig": "NoEncryption"
            },
            "CloudWatchLoggingOptions": {
                "Enabled": true,
                "LogGroupName": "/aws/kinesisfirehose/evalTelemetryFHStream",
                "LogStreamName": "S3Delivery"
            }
        },
        "ProcessingConfiguration": {
            "Enabled": false
        },
        "S3BackupMode": "Disabled",
        "CloudWatchLoggingOptions": {
            "Enabled": true,
            "LogGroupName": "/aws/kinesisfirehose/evalTelemetryFHStream",
            "LogStreamName": "RedshiftDelivery"
        }
    }
}
							</p>
							</pre>
							</div><br />
							<p>
							Highlight the text above, then copy it to your clipboard. Switch back to your console where you should be in vi, hit the "I" key to insert your text, then CTRL-V to paste the text. You then need to hit ESC then type ":wq" to write your changes and quit.
							</p>

						<h3 class="overline">PIPELINE 1 - CREATE YOUR FIREHOSE STREAMS</h3>
						<p>Your Firehose policy is ready to go! Let's apply it, then set up your log groups and Redshift.</p>
						<div class="indent-show" id="1-8-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-8-button', '1-8-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-8-content">
							<pre>
							<p id="fh-streams">
aws firehose create-delivery-stream --delivery-stream-name evalAnalyticsFHStream --delivery-stream-type KinesisStreamAsSource --kinesis-stream-source-configuration "KinesisStreamARN=arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalAnalyticsStream,RoleARN=arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role" --cli-input-json file://analyticsInput.json

aws firehose create-delivery-stream --delivery-stream-name evalTelemetryFHStream --delivery-stream-type KinesisStreamAsSource --kinesis-stream-source-configuration "KinesisStreamARN=arn:aws:kinesis:us-west-2:%ACCOUNTID%:stream/evalTelemetryStream,RoleARN=arn:aws:iam::%ACCOUNTID%:role/firehose_delivery_role" --cli-input-json file://telemetryInput.json
							</p>
							</pre>
						</div>

						<h3 class="overline">PIPELINE 1 - FIRE UP YOUR GAME BOT!</h3>
						<p>Let's fire up your game bot! You have a little web application installed on your bastion host that will propagate data from your EC2 instance to Kinesis</p>
						<div class="indent-show" id="1-9-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-9-button', '1-9-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-9-content">
							<p>1. Visit http://%BASTIONIP%/kinesis-datagen</p>
							<p>2. Enter your Kinesis stream name into the StreamName field. This should be %ANALYTICSSTREAMNAME%.</p>
							<p>3. Hit the "Generate" button.</p>
							<p></p>
							</pre>
						</div>

						<h3 class="overline">PIPELINE 1 - SET UP QUICKSIGHT</h3>
						<p>Let's get QuickSight working!</p>
						<div class="indent-show" id="1-10-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-10-button', '1-10-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-10-content">
							<p>1. Go to <span class="bold">https://quicksight.aws</span>.</p>
							<p>2. Select "Sign Up For Free" (or "Sign In" if you've used it before and have an account)</p>
							<p>3. Click on the Region in the top-right, and select "US West (Oregon)"</p>
							<p>4. Close the Welcome window</p>
							<p>5. Click the "New analysis" button in the top left</p>
							<p>6. Click the "New data set" button in the top left</p>
							<p>7. Click the "Redshift - Auto-discovered" button</p>
							<p>8. A "New Redshift data source" window will appear. For the "Data source name" enter "GamingWorkshop". For "Instance ID" click the drop-down arrow on the right of the selection box, and select "workshopcluster". The "Database name" should be automatically populated with "workshopdb", but you will need to enter a "Username" of "workshopuser" and "Password" of "workshopP4SSWORD". Click the "Validate" button on the bottom left of the window. This should turn to "Validated" with a green tick if you're successful. Click "Create data source".</p>
							<p>9. Select "eval01table" and hit the "Select" button on the bottom right</p>
							</pre>
						</div>

						<h3 class="overline">CLEANING UP YOUR ENVIRONMENT</h3>
						<p>You've created a lot of things in your account! Let's clean them up so you don't keep paying for them.</p>
						<div class="indent-show" id="1-15-button"><div class="expand"><a class="border" href="javascript:void();" onClick="reveal('1-15-button', '1-15-content')">CLICK TO TOGGLE INSTRUCTIONS</a></div></div>
						<div class="indent-hide" id="1-15-content">
							<p>
							<pre>
## Cleanup
aws iam delete-role-policy --role-name redshift_fullaccess_role --policy-name iam-redshift-policy
aws iam delete-role --role-name redshift_fullaccess_role
aws iam delete-role-policy --role-name firehose_delivery_role --policy-name iam-fh-policy
aws iam delete-role --role-name firehose_delivery_role
aws logs delete-log-group --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream"
aws logs delete-log-group --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream"
aws firehose delete-delivery-stream --delivery-stream-name evalTelemetryFHStream
aws firehose delete-delivery-stream --delivery-stream-name evalAnalyticsFHStream
aws kinesis delete-stream --stream-name evalTelemetryStream
aws kinesis delete-stream --stream-name evalAnalyticsStream
accountid="$(aws sts get-caller-identity --query "Account" --output text)"
aws s3api delete-bucket --bucket "workshop-data-%ACCOUNTID%"
aws s3api delete-bucket --bucket "workshop-bot-%ACCOUNTID%"

## QuickSight: 54.70.204.128/27

## Cleanup
#############################################################################################
## You will need to run the following commands from your laptop:
aws ec2 terminate-instances --instance-ids &lt;instance-id&gt;
aws redshift delete-cluster --cluster-identifier examplecluster --skip-final-cluster-snapshot
aws redshift delete-cluster-subnet-group --cluster-subnet-group-name workshopsubnetgroup
aws s3api delete-bucket --bucket  --region us-west-2

## Iterate for more than 1 resource, as required
aws ec2 delete-key-pair --key-name myWorkshopKeyPair
aws ec2 delete-security-group --group-id &lt;bastion-security-group-id&gt;
aws ec2 delete-security-group --group-id &lt;redshift-security-group-id&gt;
aws ec2 delete-subnet --subnet-id &lt;subnet-id1&gt;
aws ec2 delete-subnet --subnet-id &lt;subnet-id2&gt;
aws ec2 delete-subnet --subnet-id &lt;subnet-id3&gt;
aws ec2 delete-route-table --route-table-id &lt;route-table-id&gt;
aws ec2 detach-internet-gateway --internet-gateway-id &lt;igw-id&gt; --vpc-id &lt;vpc-id&gt;
aws ec2 delete-internet-gateway --internet-gateway-id &lt;igw-id&gt;
aws ec2 delete-vpc --vpc-id &lt;vpc-id&gt;
							</pre>
							</p>
						</div>

						<h3 class="overline">TO START THE WORKSHOP</h3>
						<p>... please enter the seat number for which you are seated at below:</p>
						<div class="indent-show"><div class="expand"><input type="text" id="seat">&nbsp;<a class="border" href="javascript:void();" onClick="validateSeat();">SUBMIT</a>&nbsp;<span id="message">&nbsp;</span></div></div>
					</div>
				</div>
			</div>
		</section>
	</div>
</main>

		</div>
	</div>

	<script>
		function validateSeat() {
			var seat = document.getElementById("seat").value ;
			if (isNaN(seat) || seat < 1 || seat > 99) {
				// Not valid - show error
				document.getElementById("message").innerHTML = 'Please enter a seat number between 1 & 99';
				setTimeout(function() {
					document.getElementById("message").innerHTML = '&nbsp;';
				}, 5000);
			} else {
				// Initialize the Amazon Cognito credentials provider
				AWS.config.region = 'eu-west-1'; // Region
				AWS.config.credentials = new AWS.CognitoIdentityCredentials({
					IdentityPoolId: 'eu-west-1:2067869c-18ec-4ea1-a12d-41bc840abc56',
				});

				var input = {
					seat: document.getElementById("seat").value,
					lab: '1'
				}

				var lambda = new AWS.Lambda();
				lambda.invoke({
					FunctionName: 'cmp317WorkshopUpdate',
					Payload: JSON.stringify(input)
				}, function (err, data) {
					if (err) {
						console.log(err, err.stack);
						document.getElementById("message").innerHTML = 'There was a problem registering your seat in the backend database';
						setTimeout(function() {
							document.getElementById("message").innerHTML = '&nbsp;';
						}, 5000);
					} else {
						window.location.href = '/lab_1.html?seat=' + document.getElementById("seat").value;
					}
				})

			}
		}

		function reveal(button, content) {
			if (document.getElementById(content).className == 'indent-show') {
			document.getElementById(content).className = 'indent-hide';
		} else {
			document.getElementById(content).className = 'indent-show';
		}
		}

		function changetext() {
			document.getElementById("iam-fh-policy").innerHTML = document.getElementById("iam-fh-policy").innerHTML.replace(/\%ACCOUNTID\%/g,document.getElementById("accountidinput").value);
			document.getElementById("analyticsInput").innerHTML = document.getElementById("analyticsInput").innerHTML.replace(/\%ACCOUNTID\%/g,document.getElementById("accountidinput").value);
			document.getElementById("telemetryInput").innerHTML = document.getElementById("telemetryInput").innerHTML.replace(/\%ACCOUNTID\%/g,document.getElementById("accountidinput").value);
			document.getElementById("fh-streams").innerHTML = document.getElementById("fh-streams").innerHTML.replace(/\%ACCOUNTID\%/g,document.getElementById("accountidinput").value);
		}

		function changeredshifttext() {
			document.getElementById("analyticsInput").innerHTML = document.getElementById("analyticsInput").innerHTML.replace(/\%REDSHIFTCLUSTER\%/g,document.getElementById("redshiftinput").value);
			document.getElementById("telemetryInput").innerHTML = document.getElementById("telemetryInput").innerHTML.replace(/\%REDSHIFTCLUSTER\%/g,document.getElementById("redshiftinput").value);
		}
	</script>
</body>

</html>