# https://s3-ap-southeast-2.amazonaws.com/ndd-reinvent-data/workshopguide.html

## TODO ADD STEP TO GET THE CREDENTIALS

aws configure
# Set up region=us-west-2 and keys

aws ec2 create-vpc --cidr-block 10.0.0.0/16
# Replace all following instances of <vpc-id> in this script with the "VpcId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id <vpc-id> --cidr-block 10.0.1.0/24
# Replace all following instances of <subnet-id1> in this script with the "SubnetId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id <vpc-id> --cidr-block 10.0.2.0/24
# Replace all following instances of <subnet-id2> in this script with the "SubnetId" from the JSON that is returned in your console window.
aws ec2 create-subnet --vpc-id <vpc-id> --cidr-block 10.0.3.0/24
# Replace all following instances of <subnet-id3> in this script with the "SubnetId" from the JSON that is returned in your console window.

aws ec2 create-internet-gateway
# Replace all following instances of <igw-id> in this script with the "InternetGatewayId" from the JSON that is returned in your console window.

aws ec2 attach-internet-gateway --vpc-id <vpc-id> --internet-gateway-id <igw-id>

aws ec2 create-route-table --vpc-id <vpc-id>
# Replace all following instances of <route-table-id> in this script with the "RouteTableId" from the JSON that is returned in your console window.

aws ec2 create-route --route-table-id <route-table-id> --destination-cidr-block 0.0.0.0/0 --gateway-id <igw-id>

aws ec2 describe-route-tables --route-table-id <route-table-id>
# Verify route has been created correctly. There will be two routes, the first which is the default route showing that traffic in the 10.0.0.0/16 network will stay local, and the second of which will be the route you just added, with your "GatewayId" showing and a "DestinationCidrBlock": "0.0.0.0/0" attached to it.

aws ec2 describe-subnets --filters "Name=vpc-id,Values=<vpc-id>" --query 'Subnets[*].{ID:SubnetId,CIDR:CidrBlock}'
# Extract all subnet IDs

## Choose one or more subnets to be associated with the public route, and make it a public subnet
aws ec2 associate-route-table --subnet-id <subnet-id1> --route-table-id <route-table-id>

## Enable public IP for instances created in the public subnet
aws ec2 modify-subnet-attribute --subnet-id <subnet-id1> --map-public-ip-on-launch

## Create a key pair to use for SSH access into the bastian host
aws ec2 create-key-pair --key-name myGamingKeyPair --query 'KeyMaterial' --output text > myGamingKeyPair.pem

## Grant the file owner (you!) read permission
chmod 400 myGamingKeyPair.pem

## Create security groups
aws ec2 create-security-group --group-name BastianHostAccess --description "Allow access for Bastian Host" --vpc-id <vpc-id>
# Replace all following instances of <bastian-security-group-id> in this script with the "GroupId" from the JSON that is returned in your console window.
aws ec2 create-security-group --group-name RedshiftAccess --description "Allow access for Redshift" --vpc-id <vpc-id>
# Replace all following instances of <redshift-security-group-id> in this script with the "GroupId" from the JSON that is returned in your console window.

# Add rule to allow SSH access to the Bastian Host from *anywhere*
aws ec2 authorize-security-group-ingress --group-id <bastian-security-group-id> --protocol tcp --port 22 --cidr 0.0.0.0/0
aws ec2 authorize-security-group-ingress --group-id <redshift-security-group-id> --protocol tcp --port 5439 --cidr 0.0.0.0/0

# Add rule to allow SSH access to Redshift from Quicksight
aws ec2 authorize-security-group-ingress --group-id <redshift-security-group-id> --protocol tcp --port 5439 --cidr 54.70.204.128/27

## Now create the Bastian Host (based on an AMI we prepared earlier) (Nirav's bastion AMI in us-west-2 is ami-dbec22a3)
aws ec2 run-instances --image-id ami-e2822398 --count 1 --instance-type t2.micro --key-name myGamingKeyPair --security-group-ids <redshift-security-group-id> --subnet-id <subnet-id1>
# Replace all following instances of <instance-id> in this script with the "InstanceId" from the JSON that is returned in your console window.

## Get the public IP so that you can connect to it
aws ec2 describe-instances --instance-id <instance-id> --query 'Reservations[*].Instances[*].PublicIpAddress' --output=text
# Replace all following instances of <public-ip-address> in this script with the IP address that is returned in your console window.

# Add rule to allow SSH access to Redshift from the Bastian Host
aws ec2 authorize-security-group-ingress --group-id <redshift-security-group-id> --protocol tcp --port 5439 --cidr <public-ip-address>

## Get into the instance
ssh -i myGamingKeyPair.pem ec2-user@<public-ip-address>

#############################################################################################

##Configure the AWS CLI
aws configure
# Set up region=us-west-2 and keys

## Store your AWS Account ID as a variable
accountid="$(aws sts get-caller-identity --query "Account" --output text)"
## Create an S3 bucket for your game telemetry files
# aws s3api create-bucket --bucket "workshop-data-${accountid}" --acl private --create-bucket-configuration LocationConstraint=us-west-2
## Create an S3 bucket for your game bot
aws s3api create-bucket --bucket "workshop-bot-${accountid}" --acl private --create-bucket-configuration LocationConstraint=us-west-2

## WE NEED TO ENSURE THE JSON IS IN THEIR ROOT USER FOLDER
## Create a role for Redshift from the policy document provided
aws iam create-role --role-name redshift_fullaccess_role --assume-role-policy-document file://iam-base-redshift-policy.json
## Apply a policy to the role to allow full access to Redshift
aws iam put-role-policy --role-name redshift_fullaccess_role --policy-name iam-redshift-policy --policy-document file://iam-redshift-policy.json

## Create your Kinesis stream for telemetry
aws kinesis create-stream --stream-name evalTelemetryStream --shard-count 10
## Create your Kinesis stream for analytics
aws kinesis create-stream --stream-name evalAnalyticsStream --shard-count 10

## Create a role for Firehose from the policy document provided
aws iam create-role --role-name firehose_delivery_role --assume-role-policy-document file://iam-base-fh-policy.json
## Apply a policy to the role to allow full access to Firehose
aws iam put-role-policy --role-name firehose_delivery_role --policy-name iam-fh-policy --policy-document file://iam-fh-policy.json

## Create a log group and streams for telemetry
aws logs create-log-group  --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream" --log-stream-name "S3Delivery"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream" --log-stream-name "RedshiftDelivery"

## Create a log group and streams for analytics
aws logs create-log-group  --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream" --log-stream-name "S3Delivery"
aws logs create-log-stream --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream" --log-stream-name "RedshiftDelivery"

## TODO NEED TO CREATE REDSHIFT CLUSTER
aws redshift create-cluster-subnet-group --cluster-subnet-group-name workshopsubnetgroup  --description "My subnet group for the workshop" --subnet-ids <subnet-id1> <subnet-id2> <subnet-id3>
aws redshift create-cluster --cluster-identifier examplecluster --master-username evaluser --master-user-password evalP4s$w0rd1 --cluster-type single-node --node-type ds2.xlarge --cluster-type single-node --db-name evaldb --cluster-subnet-group-name workshopsubnetgroup --vpc-security-group-ids <redshift-security-group-id> 

## TODO NEED TO UPDATE THE JSON
aws firehose create-delivery-stream --delivery-stream-name evalAnalyticsFHStream --delivery-stream-type KinesisStreamAsSource --kinesis-stream-source-configuration "KinesisStreamARN=arn:aws:kinesis:us-west-2:${accountid}:stream/evalAnalyticsStream,RoleARN=arn:aws:iam::${accountid}:role/firehose_delivery_role" --cli-input-json file://analyticsInput.json

aws firehose create-delivery-stream --delivery-stream-name evalTelemetryFHStream --delivery-stream-type KinesisStreamAsSource --kinesis-stream-source-configuration "KinesisStreamARN=arn:aws:kinesis:us-west-2:${accountid}:stream/evalTelemetryStream,RoleARN=arn:aws:iam::${accountid}:role/firehose_delivery_role" --cli-input-json file://telemetryInput.json


## Cleanup
aws iam delete-role-policy --role-name redshift_fullaccess_role --policy-name iam-redshift-policy
aws iam delete-role --role-name redshift_fullaccess_role
aws iam delete-role-policy --role-name firehose_delivery_role --policy-name iam-fh-policy
aws iam delete-role --role-name firehose_delivery_role
aws logs delete-log-group --log-group-name "/aws/kinesisfirehose/evalTelemetryFHStream"
aws logs delete-log-group --log-group-name "/aws/kinesisfirehose/evalAnalyticsFHStream"
aws firehose delete-delivery-stream --delivery-stream-name evalTelemetryFHStream
aws firehose delete-delivery-stream --delivery-stream-name evalAnalyticsFHStream
aws kinesis delete-stream --stream-name evalTelemetryStream
aws kinesis delete-stream --stream-name evalAnalyticsStream

aws s3api delete-bucket --bucket kinesis-bot-datagen
# aws s3api delete-bucket --bucket --bucket "workshop-data-${aws sts get-caller-identity --query "Account" --output text}"

## QuickSight: 54.70.204.128/27


## Cleanup
#############################################################################################
## Terminate Bastian Host instance
aws ec2 terminate-instances --instance-ids <instance-id>


## Iterate for more than 1 resource, as required
aws ec2 delete-security-group --group-id <bastian-security-group-id>
aws ec2 delete-security-group --group-id <redshift-security-group-id>
aws ec2 delete-subnet --subnet-id <subnet-id1>
aws ec2 delete-subnet --subnet-id <subnet-id2>
aws ec2 delete-subnet --subnet-id <subnet-id3>
aws ec2 delete-route-table --route-table-id <route-table-id>
aws ec2 detach-internet-gateway --internet-gateway-id <igw-id> --vpc-id <vpc-id>
aws ec2 delete-internet-gateway --internet-gateway-id <igw-id>
aws ec2 delete-vpc --vpc-id <vpc-id>